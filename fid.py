# -*- coding: utf-8 -*-
"""FID.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nyRUXXszYLPIH5K3e1woUgnZIRqdhurV
"""

#pip install torch torchvision torcheval
#pip install torchmetrics
#pip install torchmetrics[image]

from datasets import load_dataset

coco_dataset = load_dataset(
    "sayakpaul/coco-30-val-2014",
    cache_dir="/scratch/gilbreth/bui46/huggingface_cache/datasets"
)["train"]

model_name = "CompVis/stable-diffusion-v1-4"
#model_name = "stabilityai/stable-diffusion-2-1-base"
#model_name = "stabilityai/sdxl-turbo"
#model_name = "amused/amused-512"


# --------------------------------------- DEFINE PROMPTS ---------------------------------------- #
prompts = []
with open('Prompt_Benchmark.txt', 'r') as file: #found on team google drive
    for idx, line in enumerate(file):
      if (idx == 10):
        break
      prompts.append(line)
# ----------------------------------------------------------------------------------------------- #

import time, torch, psutil, threading, matplotlib.pyplot as plt
from diffusers import StableDiffusionPipeline, AutoPipelineForText2Image, AmusedPipeline
from PIL import Image
import pynvml
import os

# Redirect all Hugging Face caching to your scratch space
os.environ["HF_HOME"] = "/scratch/gilbreth/bui46/huggingface_cache"
os.environ["HF_HUB_CACHE"] = "/scratch/gilbreth/bui46/huggingface_cache/hub"
os.environ["TRANSFORMERS_CACHE"] = "/scratch/gilbreth/bui46/huggingface_cache/transformers"
os.environ["DIFFUSERS_CACHE"] = "/scratch/gilbreth/bui46/huggingface_cache/diffusers"

# Resource utilization tracking variables
cpu_usage = []
ram_usage = []
gpu_usage = []
vram_usage = []
timestamps = []
prompt_end_times = []
monitoring = True
def monitor_resources():
    global monitoring
    while monitoring:
        current_time = time.time() - start_time
        cpu_usage.append(psutil.cpu_percent())
        ram_usage.append(psutil.virtual_memory().used / (1024 ** 3))  # Convert bytes to GB
        gpu_usage.append(torch.cuda.utilization())
        vram_usage.append(torch.cuda.memory_allocated() / (1024 ** 3))  # Convert bytes to GB
        timestamps.append(current_time)
        time.sleep(0.1)  # Polling rate

def get_baseline_usage():
    return {
        'cpu': psutil.cpu_percent(),
        'ram': psutil.virtual_memory().used / (1024 ** 3),  # Convert bytes to GB
        'gpu': torch.cuda.utilization(),
        'vram': torch.cuda.memory_allocated() / (1024 ** 3)  # Convert bytes to GB
    }
baseline_usage = get_baseline_usage()
start_time = time.time()
monitor_thread = threading.Thread(target=monitor_resources)
monitor_thread.start()

# -------------------------------------------- PIPELINE LIBRARY -------------------------------------------- #
cache_path = "/scratch/gilbreth/bui46/huggingface_cache"

if model_name == "CompVis/stable-diffusion-v1-4" or model_name == "stabilityai/stable-diffusion-2-1-base":
    pipe = StableDiffusionPipeline.from_pretrained(model_name, cache_dir=cache_path)
elif model_name == "stabilityai/sdxl-turbo":
    pipe = AutoPipelineForText2Image.from_pretrained(
        model_name, torch_dtype=torch.float16, variant="fp16", cache_dir=cache_path
    )
elif model_name == "amused/amused-512":
    pipe = AmusedPipeline.from_pretrained(
        model_name, variant="fp16", torch_dtype=torch.float16, cache_dir=cache_path
    )
else:
    print("No associated pipe exists. Please add the associated pipe to the pipeline library!")
    quit()
pipe.to("cuda")
# ---------------------------------------------------------------------------------------------------------- #

pipeline_loading_time = time.time()
target_size = (768, 768)
# Generate images for each prompt
times = []
for i, prompt in enumerate(prompts):
    # Calculate image generation time
    start_prompt_time = time.time()
    # image = pipe(prompt, height=target_size[1], width=target_size[0]).images[0] # use this for models 1, 2, 3
    image = pipe(prompt, generator=torch.manual_seed(0)).images[0] # use this for Amused
    end_prompt_time = time.time()
    elapsed_time = end_prompt_time - start_prompt_time
    times.append(elapsed_time)

    # Save image and clear cache
    filename = f"{prompt.replace(' ', '_')}_image.png"
    save_dir = "generated_images"
    if not os.path.exists(save_dir):
        os.makedirs(save_dir)


    full_path = os.path.join(save_dir, filename)

    image = image.resize(target_size, Image.LANCZOS)
    image.save(full_path)
    print(f"Time taken for prompt '{prompt}': {elapsed_time:.2f} seconds")
    # torch.cuda.empty_cache()
    prompt_end_times.append(end_prompt_time - start_time)


# Stop resource monitoring
monitoring = False
monitor_thread.join()

#sudo apt install imagemagick
#pip install wand

# # Make blurred versions of the generated images
# from wand.image import Image

# save_dir = "distorted_images"
# if not os.path.exists(save_dir):
#   os.makedirs(save_dir)

# save_dir = "more_distorted_images"
# if not os.path.exists(save_dir):
#   os.makedirs(save_dir)

# for f in os.listdir('/content/generated_images'):
#     print(f)
#     with Image(filename = f'/content/generated_images/{f}') as img:
#         img.blur(radius=5, sigma=3)
#         img.save(filename=f'/content/distorted_images/distorted_{f}')
#         img.blur(radius=100, sigma=60)
#         img.save(filename=f'/content/more_distorted_images/more_distorted_{f}')


import os
import random
from PIL import Image, ImageDraw

input_dir = "/scratch/gilbreth/bui46/test/generated_images"
distorted_dir = "/scratch/gilbreth/bui46/test/distorted_images"
more_distorted_dir = "/scratch/gilbreth/bui46/test/more_distorted_images"
os.makedirs(distorted_dir, exist_ok=True)
os.makedirs(more_distorted_dir, exist_ok=True)

# Corrupt image using blocky chunks of pixels
def corrupt_blocks(img, block_size=10, num_blocks=100):
    img = img.convert('RGB')
    corrupted = img.copy()
    draw = ImageDraw.Draw(corrupted)
    width, height = img.size

    for _ in range(num_blocks):
        x0 = random.randint(0, width - block_size)
        y0 = random.randint(0, height - block_size)
        x1 = x0 + random.randint(1, block_size)
        y1 = y0 + random.randint(1, block_size)
        random_color = (
            random.randint(0, 255),
            random.randint(0, 255),
            random.randint(0, 255)
        )
        draw.rectangle([x0, y0, x1, y1], fill=random_color)

    return corrupted

for f in os.listdir(input_dir):
    if f.lower().endswith(('.png', '.jpg', '.jpeg')):
        print(f"Processing {f}")
        img_path = os.path.join(input_dir, f)
        img = Image.open(img_path)

        # Light corruption (small blocks, fewer)
        distorted = corrupt_blocks(img, block_size=10, num_blocks=150)
        distorted.save(os.path.join(distorted_dir, f"distorted_{f}"))

        # Heavier corruption (larger blocks, more)
        more_distorted = corrupt_blocks(img, block_size=60, num_blocks=150)
        more_distorted.save(os.path.join(more_distorted_dir, f"more_distorted_{f}"))

import os
import torch
import torchvision.models as models
import torchvision.transforms as transforms
from PIL import Image
import matplotlib.pyplot as plt
from torchmetrics.image.fid import FrechetInceptionDistance
import math

plt_prompts = []

def run(input_prompt, letter):
    # Initialize Inception v3 for FID
    model = models.inception_v3(pretrained=True, transform_input=False)
    model.fc = torch.nn.Identity()
    model.eval()
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = model.to(device)

    preprocess = transforms.Compose([
        transforms.Resize(299),
        transforms.CenterCrop(299),
        transforms.ToTensor(),
        transforms.Lambda(lambda x: (x * 255).byte())
    ])

    # Load generated image
    ref_filename = f"{input_prompt.replace(' ', '_')}_image.png"
    gen_image = Image.open(f"/scratch/gilbreth/bui46/test/generated_images/{ref_filename}")

    # Load distorted versions (optional but needed for plotting)
    dist_image = Image.open(f"/scratch/gilbreth/bui46/test/distorted_images/distorted_{ref_filename}")
    more_dist_image = Image.open(f"/scratch/gilbreth/bui46/test/more_distorted_images/more_distorted_{ref_filename}")

    # Load corresponding COCO-30 image by index
    #idx = prompts.index(input_prompt)
    #coco_image = coco_dataset[idx]['image']

    from datasets import load_dataset
    import time

    scratch_cache_dir = "/scratch/gilbreth/bui46/huggingface_cache/datasets"
    output_file = "/scratch/gilbreth/bui46/test/coco_captions.txt"

    try:
        print("Attempting to load COCO dataset from scratch cache...")
        ds = load_dataset("sayakpaul/coco-30-val-2014", cache_dir=scratch_cache_dir)
        print("✅ Successfully loaded COCO dataset from scratch cache!")
    except:
        print("⚠️ Cache not available, attempting download to scratch...")
        try:
            ds = load_dataset("sayakpaul/coco-30-val-2014", cache_dir=scratch_cache_dir)
            print("✅ Successfully downloaded COCO dataset to scratch!")
        except Exception as e:
            print(f"❌ Failed to download dataset: {e}")
            print("⏳ Waiting 60 seconds before retry...")
            time.sleep(60)
            try:
                ds = load_dataset("sayakpaul/coco-30-val-2014", cache_dir=scratch_cache_dir)
                print("✅ Successfully loaded dataset after retry!")
            except:
                print("❌ Failed again. Try again later or switch to an alternative dataset.")
                quit()
    coco_dataset = ds["train"]

    # Find matching COCO-30 image based on prompt text
    coco_image = None
    with open(output_file, "w", encoding="utf-8") as f:
        for example in coco_dataset:
            caption = example['caption']
            f.write(f"{i}: {caption}\n")
            if input_prompt.strip().lower() in example['caption'].strip().lower():
                print("Found image in dataset")
                coco_image = example['image']
                break

    if coco_image is None:
        raise ValueError(f"No matching COCO image found for prompt: {input_prompt}")

    # Preprocess all images
    gen_tensor = preprocess(gen_image).unsqueeze(0).to(device)
    dist_tensor = preprocess(dist_image).unsqueeze(0).to(device)
    more_dist_tensor = preprocess(more_dist_image).unsqueeze(0).to(device)
    coco_tensor = preprocess(coco_image).unsqueeze(0).to(device)

    fid = FrechetInceptionDistance(feature=2048, normalize=True).to(device)

    # FID: Generated vs COCO-30 (main score)
    fid.update(coco_tensor.repeat(2, 1, 1, 1), real=True)
    fid.update(gen_tensor.repeat(2, 1, 1, 1), real=False)
    fid_score_gen = fid.compute().item()
    fid.reset()

    # FID: Generated vs Distorted
    fid.update(dist_tensor.repeat(2, 1, 1, 1), real=True)
    fid.update(gen_tensor.repeat(2, 1, 1, 1), real=False)
    fid_score_dist = fid.compute().item()
    fid.reset()

    # FID: Generated vs More Distorted
    fid.update(more_dist_tensor.repeat(2, 1, 1, 1), real=True)
    fid.update(gen_tensor.repeat(2, 1, 1, 1), real=False)
    fid_score_more_dist = fid.compute().item()

    # Normalize (sigmoid-style) for visualization
    norm = lambda x: 1.0 / (1.0 + math.exp(-0.01 * (x - 400)))
    fid_score_gen = norm(fid_score_gen)
    fid_score_dist = norm(fid_score_dist)
    fid_score_more_dist = norm(fid_score_more_dist)

    # Plot
    fig, axes = plt.subplots(1, 4, figsize=(12, 5))
    axes[0].imshow(gen_image)
    axes[0].set_title("Generated")
    axes[0].axis("off")
    axes[1].imshow(coco_image)
    axes[1].set_title("COCO-30")
    axes[1].axis("off")
    axes[2].imshow(dist_image)
    axes[2].set_title("Distorted")
    axes[2].axis("off")
    axes[3].imshow(more_dist_image)
    axes[3].set_title("More Distorted")
    axes[3].axis("off")

    plt.suptitle(
        f"Gen Score: {fid_score_gen:.2f}, Dis Score: {fid_score_dist:.2f}, More Dis: {fid_score_more_dist:.2f}\nPrompt: {input_prompt}",
        fontsize=10
    )

    results_dir = '/scratch/gilbreth/bui46/test/results'
    os.makedirs(results_dir, exist_ok=True)
    plt.savefig(f'{results_dir}/{letter}.png')
    plt.close()

char = 'a'

for input_prompt in prompts:
    run(input_prompt, char)
    char = chr(ord(char) + 1)